/*
 * Copyright (c) Microsoft Corporation. All rights reserved.
 * Licensed under the MIT License. See License.txt in the project root for license information.
 *
 * Code generated by Microsoft (R) AutoRest Code Generator.
 * Changes may cause incorrect behavior and will be lost if the code is regenerated.
 */

import { BaseResource, CloudError, AzureServiceClientOptions } from "@azure/ms-rest-azure-js";
import * as msRest from "@azure/ms-rest-js";

export { BaseResource, CloudError };

/**
 * Graph system data.
 */
export interface MediaGraphSystemData {
  /**
   * The timestamp of resource creation (UTC).
   */
  createdAt?: Date;
  /**
   * The timestamp of resource last modification (UTC).
   */
  lastModifiedAt?: Date;
}

/**
 * A key, value pair. The graph topology can be authored with certain values with parameters. Then,
 * during graph instance creation, the value for that parameters can be specified. This allows the
 * same graph topology to be used as a blueprint for multiple graph instances with different values
 * for the parameters.
 */
export interface MediaGraphParameterDefinition {
  /**
   * Name of parameter as defined in the graph topology.
   */
  name: string;
  /**
   * Value of parameter.
   */
  value: string;
}

/**
 * Properties of a Media Graph instance.
 */
export interface MediaGraphInstanceProperties {
  /**
   * An optional description for the instance.
   */
  description?: string;
  /**
   * The name of the graph topology that this instance will run. A topology with this name should
   * already have been set in the Edge module.
   */
  topologyName?: string;
  /**
   * List of one or more graph instance parameters.
   */
  parameters?: MediaGraphParameterDefinition[];
  /**
   * Allowed states for a graph Instance. Possible values include: 'Inactive', 'Activating',
   * 'Active', 'Deactivating'
   */
  state?: MediaGraphInstanceState;
}

/**
 * Represents a Media Graph instance.
 */
export interface MediaGraphInstance {
  name: string;
  apiVersion?: string;
  systemData?: MediaGraphSystemData;
  properties?: MediaGraphInstanceProperties;
}

/**
 * Collection of graph instances.
 */
export interface MediaGraphInstanceCollection {
  /**
   * Collection of graph instances.
   */
  value?: MediaGraphInstance[];
  /**
   * Continuation token to use in subsequent calls to enumerate through the graph instance
   * collection (when the collection contains too many results to return in one response).
   */
  continuationToken?: string;
}

/**
 * The declaration of a parameter in the graph topology. A graph topology can be authored with
 * parameters. Then, during graph instance creation, the value for those parameters can be
 * specified. This allows the same graph topology to be used as a blueprint for multiple graph
 * instances with different values for the parameters.
 */
export interface MediaGraphParameterDeclaration {
  /**
   * The name of the parameter.
   */
  name: string;
  /**
   * Possible values include: 'String', 'SecretString', 'Int', 'Double', 'Bool'
   */
  type: MediaGraphParameterType;
  /**
   * Description of the parameter.
   */
  description?: string;
  /**
   * The default value for the parameter, to be used if the graph instance does not specify a
   * value.
   */
  default?: string;
}

/**
 * Contains the possible cases for MediaGraphSource.
 */
export type MediaGraphSourceUnion = MediaGraphSource | MediaGraphRtspSource | MediaGraphIoTHubMessageSource;

/**
 * Media graph source.
 */
export interface MediaGraphSource {
  /**
   * Polymorphic Discriminator
   */
  type: "MediaGraphSource";
  /**
   * The name to be used for this source node.
   */
  name: string;
}

/**
 * Allows for the selection of particular streams from another node.
 */
export interface MediaGraphOutputSelector {
  /**
   * The stream property to compare with. Possible values include: 'mediaType'
   */
  property?: MediaGraphOutputSelectorProperty;
  /**
   * The operator to compare streams by. Possible values include: 'is', 'isNot'
   */
  operator?: MediaGraphOutputSelectorOperator;
  /**
   * Value to compare against.
   */
  value?: string;
}

/**
 * Represents the input to any node in a media graph.
 */
export interface MediaGraphNodeInput {
  /**
   * The name of another node in the media graph, the output of which is used as input to this
   * node.
   */
  nodeName?: string;
  /**
   * Allows for the selection of particular streams from another node.
   */
  outputSelectors?: MediaGraphOutputSelector[];
}

/**
 * Contains the possible cases for MediaGraphProcessor.
 */
export type MediaGraphProcessorUnion = MediaGraphProcessor | MediaGraphMotionDetectionProcessor | MediaGraphExtensionProcessorBaseUnion | MediaGraphSignalGateProcessor | MediaGraphFrameRateFilterProcessor;

/**
 * A node that represents the desired processing of media in a graph. Takes media and/or events as
 * inputs, and emits media and/or event as output.
 */
export interface MediaGraphProcessor {
  /**
   * Polymorphic Discriminator
   */
  type: "MediaGraphProcessor";
  /**
   * The name for this processor node.
   */
  name: string;
  /**
   * An array of the names of the other nodes in the media graph, the outputs of which are used as
   * input for this processor node.
   */
  inputs: MediaGraphNodeInput[];
}

/**
 * Contains the possible cases for MediaGraphSink.
 */
export type MediaGraphSinkUnion = MediaGraphSink | MediaGraphIoTHubMessageSink | MediaGraphFileSink | MediaGraphAssetSink;

/**
 * Enables a media graph to write media data to a destination outside of the Live Video Analytics
 * IoT Edge module.
 */
export interface MediaGraphSink {
  /**
   * Polymorphic Discriminator
   */
  type: "MediaGraphSink";
  /**
   * Name to be used for the media graph sink.
   */
  name: string;
  /**
   * An array of the names of the other nodes in the media graph, the outputs of which are used as
   * input for this sink node.
   */
  inputs: MediaGraphNodeInput[];
}

/**
 * Describes the properties of a graph topology.
 */
export interface MediaGraphTopologyProperties {
  description?: string;
  parameters?: MediaGraphParameterDeclaration[];
  sources?: MediaGraphSourceUnion[];
  processors?: MediaGraphProcessorUnion[];
  sinks?: MediaGraphSinkUnion[];
}

/**
 * Describes a graph topology.
 */
export interface MediaGraphTopology {
  name: string;
  apiVersion?: string;
  systemData?: MediaGraphSystemData;
  properties?: MediaGraphTopologyProperties;
}

/**
 * Collection of graph topologies.
 */
export interface MediaGraphTopologyCollection {
  /**
   * Collection of graph topologies.
   */
  value?: MediaGraphTopology[];
  /**
   * Continuation token to use in subsequent calls to enumerate through the graph topologies
   * collection (when the collection contains too many results to return in one response).
   */
  continuationToken?: string;
}

/**
 * Contains the possible cases for MediaGraphCredentials.
 */
export type MediaGraphCredentialsUnion = MediaGraphCredentials | MediaGraphUsernamePasswordCredentials | MediaGraphHttpHeaderCredentials;

/**
 * Credentials to present during authentication.
 */
export interface MediaGraphCredentials {
  /**
   * Polymorphic Discriminator
   */
  type: "MediaGraphCredentials";
}

/**
 * Contains the possible cases for MediaGraphEndpoint.
 */
export type MediaGraphEndpointUnion = MediaGraphEndpoint | MediaGraphUnsecuredEndpoint | MediaGraphTlsEndpoint;

/**
 * Base class for endpoints.
 */
export interface MediaGraphEndpoint {
  /**
   * Polymorphic Discriminator
   */
  type: "MediaGraphEndpoint";
  /**
   * Polymorphic credentials to be presented to the endpoint.
   */
  credentials?: MediaGraphCredentialsUnion;
  /**
   * Url for the endpoint.
   */
  url: string;
}

/**
 * Enables a graph to capture media from a RTSP server.
 */
export interface MediaGraphRtspSource {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphRtspSource";
  /**
   * The name to be used for this source node.
   */
  name: string;
  /**
   * Underlying RTSP transport. This is used to enable or disable HTTP tunneling. Possible values
   * include: 'Http', 'Tcp'
   */
  transport?: MediaGraphRtspTransport;
  /**
   * RTSP endpoint of the stream that is being connected to.
   */
  endpoint: MediaGraphEndpointUnion;
}

/**
 * Enables a graph to receive messages via routes declared in the IoT Edge deployment manifest.
 */
export interface MediaGraphIoTHubMessageSource {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphIoTHubMessageSource";
  /**
   * The name to be used for this source node.
   */
  name: string;
  /**
   * Name of the input path where messages can be routed to (via routes declared in the IoT Edge
   * deployment manifest).
   */
  hubInputName?: string;
}

/**
 * Enables a graph to publish messages that can be delivered via routes declared in the IoT Edge
 * deployment manifest.
 */
export interface MediaGraphIoTHubMessageSink {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphIoTHubMessageSink";
  /**
   * Name to be used for the media graph sink.
   */
  name: string;
  /**
   * An array of the names of the other nodes in the media graph, the outputs of which are used as
   * input for this sink node.
   */
  inputs: MediaGraphNodeInput[];
  /**
   * Name of the output path to which the graph will publish message. These messages can then be
   * delivered to desired destinations by declaring routes referencing the output path in the IoT
   * Edge deployment manifest.
   */
  hubOutputName?: string;
}

/**
 * Username/password credential pair.
 */
export interface MediaGraphUsernamePasswordCredentials {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphUsernamePasswordCredentials";
  /**
   * Username for a username/password pair.
   */
  username: string;
  /**
   * Password for a username/password pair.
   */
  password?: string;
}

/**
 * Http header service credentials.
 */
export interface MediaGraphHttpHeaderCredentials {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphHttpHeaderCredentials";
  /**
   * HTTP header name.
   */
  headerName: string;
  /**
   * HTTP header value.
   */
  headerValue: string;
}

/**
 * An endpoint that the media graph can connect to, with no encryption in transit.
 */
export interface MediaGraphUnsecuredEndpoint {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphUnsecuredEndpoint";
  /**
   * Polymorphic credentials to be presented to the endpoint.
   */
  credentials?: MediaGraphCredentialsUnion;
  /**
   * Url for the endpoint.
   */
  url: string;
}

/**
 * Contains the possible cases for MediaGraphCertificateSource.
 */
export type MediaGraphCertificateSourceUnion = MediaGraphCertificateSource | MediaGraphPemCertificateList;

/**
 * Base class for certificate sources.
 */
export interface MediaGraphCertificateSource {
  /**
   * Polymorphic Discriminator
   */
  type: "MediaGraphCertificateSource";
}

/**
 * Options for controlling the authentication of TLS endpoints.
 */
export interface MediaGraphTlsValidationOptions {
  /**
   * Boolean value ignoring the host name (common name) during validation.
   */
  ignoreHostname?: string;
  /**
   * Boolean value ignoring the integrity of the certificate chain at the current time.
   */
  ignoreSignature?: string;
}

/**
 * An endpoint that the graph can connect to, which must be connected over TLS/SSL.
 */
export interface MediaGraphTlsEndpoint {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphTlsEndpoint";
  /**
   * Polymorphic credentials to be presented to the endpoint.
   */
  credentials?: MediaGraphCredentialsUnion;
  /**
   * Url for the endpoint.
   */
  url: string;
  /**
   * Trusted certificates when authenticating a TLS connection. Null designates that Azure Media
   * Service's source of trust should be used.
   */
  trustedCertificates?: MediaGraphCertificateSourceUnion;
  /**
   * Validation options to use when authenticating a TLS connection. By default, strict validation
   * is used.
   */
  validationOptions?: MediaGraphTlsValidationOptions;
}

/**
 * A list of PEM formatted certificates.
 */
export interface MediaGraphPemCertificateList {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphPemCertificateList";
  /**
   * PEM formatted public certificates one per entry.
   */
  certificates: string[];
}

/**
 * Enables a media graph to write/store media (video and audio) to a file on the Edge device.
 */
export interface MediaGraphFileSink {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphFileSink";
  /**
   * Name to be used for the media graph sink.
   */
  name: string;
  /**
   * An array of the names of the other nodes in the media graph, the outputs of which are used as
   * input for this sink node.
   */
  inputs: MediaGraphNodeInput[];
  /**
   * Absolute file path pattern for creating new files on the Edge device.
   */
  filePathPattern: string;
}

/**
 * Enables a graph to record media to an Azure Media Services asset, for subsequent playback.
 */
export interface MediaGraphAssetSink {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphAssetSink";
  /**
   * Name to be used for the media graph sink.
   */
  name: string;
  /**
   * An array of the names of the other nodes in the media graph, the outputs of which are used as
   * input for this sink node.
   */
  inputs: MediaGraphNodeInput[];
  /**
   * A name pattern when creating new assets.
   */
  assetNamePattern?: string;
  /**
   * When writing media to an asset, wait until at least this duration of media has been
   * accumulated on the Edge. Expressed in increments of 30 seconds, with a minimum of 30 seconds
   * and a recommended maximum of 5 minutes.
   */
  segmentLength?: string;
  /**
   * Path to a local file system directory for temporary caching of media, before writing to an
   * Asset. Used when the Edge device is temporarily disconnected from Azure.
   */
  localMediaCachePath?: string;
  /**
   * Maximum amount of disk space that can be used for temporary caching of media.
   */
  localMediaCacheMaximumSizeMiB?: string;
}

/**
 * A node that accepts raw video as input, and detects if there are moving objects present. If so,
 * then it emits an event, and allows frames where motion was detected to pass through. Other
 * frames are blocked/dropped.
 */
export interface MediaGraphMotionDetectionProcessor {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphMotionDetectionProcessor";
  /**
   * The name for this processor node.
   */
  name: string;
  /**
   * An array of the names of the other nodes in the media graph, the outputs of which are used as
   * input for this processor node.
   */
  inputs: MediaGraphNodeInput[];
  /**
   * Enumeration that specifies the sensitivity of the motion detection processor. Possible values
   * include: 'Low', 'Medium', 'High'
   */
  sensitivity?: MediaGraphMotionDetectionSensitivity;
  /**
   * Indicates whether the processor should detect and output the regions, within the video frame,
   * where motion was detected. Default is true.
   */
  outputMotionRegion?: boolean;
}

/**
 * The scaling mode for the image.
 */
export interface MediaGraphImageScale {
  /**
   * Describes the modes for scaling an input video frame into an image, before it is sent to an
   * inference engine. Possible values include: 'PreserveAspectRatio', 'Pad', 'Stretch'
   */
  mode?: MediaGraphImageScaleMode;
  /**
   * The desired output width of the image.
   */
  width?: string;
  /**
   * The desired output height of the image.
   */
  height?: string;
}

/**
 * Contains the possible cases for MediaGraphImageFormat.
 */
export type MediaGraphImageFormatUnion = MediaGraphImageFormat | MediaGraphImageFormatRaw | MediaGraphImageFormatEncoded;

/**
 * Encoding settings for an image.
 */
export interface MediaGraphImageFormat {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphImageFormat";
}

/**
 * Describes the properties of an image frame.
 */
export interface MediaGraphImage {
  scale?: MediaGraphImageScale;
  format?: MediaGraphImageFormatUnion;
}

/**
 * Contains the possible cases for MediaGraphExtensionProcessorBase.
 */
export type MediaGraphExtensionProcessorBaseUnion = MediaGraphExtensionProcessorBase | MediaGraphHttpExtension;

/**
 * Processor that allows for extensions, outside of the Live Video Analytics Edge module, to be
 * integrated into the graph. It is the base class for various different kinds of extension
 * processor types.
 */
export interface MediaGraphExtensionProcessorBase {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphExtensionProcessorBase";
  /**
   * The name for this processor node.
   */
  name: string;
  /**
   * An array of the names of the other nodes in the media graph, the outputs of which are used as
   * input for this processor node.
   */
  inputs: MediaGraphNodeInput[];
  /**
   * Endpoint to which this processor should connect.
   */
  endpoint?: MediaGraphEndpointUnion;
  /**
   * Describes the parameters of the image that is sent as input to the endpoint.
   */
  image?: MediaGraphImage;
}

/**
 * A processor that allows the media graph to send video frames (mostly at low frame rates e.g. <5
 * fps) to external inference container by leveraging HTTP based RESTful API. It then retrieves the
 * inference results and relays them downstream to the next node.
 */
export interface MediaGraphHttpExtension {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphHttpExtension";
  /**
   * The name for this processor node.
   */
  name: string;
  /**
   * An array of the names of the other nodes in the media graph, the outputs of which are used as
   * input for this processor node.
   */
  inputs: MediaGraphNodeInput[];
  /**
   * Endpoint to which this processor should connect.
   */
  endpoint?: MediaGraphEndpointUnion;
  /**
   * Describes the parameters of the image that is sent as input to the endpoint.
   */
  image?: MediaGraphImage;
}

/**
 * Encoding settings for raw images.
 */
export interface MediaGraphImageFormatRaw {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphImageFormatRaw";
  /**
   * Possible values include: 'Yuv420p', 'Rgb565be', 'Rgb565le', 'Rgb555be', 'Rgb555le', 'Rgb24',
   * 'Bgr24', 'Argb', 'Rgba', 'Abgr', 'Bgra'
   */
  pixelFormat?: MediaGraphImageFormatRawPixelFormat;
}

/**
 * Allowed formats for the image.
 */
export interface MediaGraphImageFormatEncoded {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphImageFormatEncoded";
  /**
   * The different encoding formats that can be used for the image. Possible values include:
   * 'Jpeg', 'Bmp', 'Png'. Default value: 'Jpeg'.
   */
  encoding?: MediaGraphImageEncodingFormat;
  /**
   * The image quality (used for JPEG only). Value must be between 0 to 100 (best quality).
   */
  quality?: string;
}

/**
 * A signal gate determines when to block (gate) incoming media, and when to allow it through. It
 * gathers input events over the activationEvaluationWindow, and determines whether to open or
 * close the gate.
 */
export interface MediaGraphSignalGateProcessor {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphSignalGateProcessor";
  /**
   * The name for this processor node.
   */
  name: string;
  /**
   * An array of the names of the other nodes in the media graph, the outputs of which are used as
   * input for this processor node.
   */
  inputs: MediaGraphNodeInput[];
  /**
   * The period of time over which the gate gathers input events, before evaluating them.
   */
  activationEvaluationWindow?: string;
  /**
   * Signal offset once the gate is activated (can be negative). It is an offset between the time
   * the event is received, and the timestamp of the first media sample (eg. video frame) that is
   * allowed through by the gate.
   */
  activationSignalOffset?: string;
  /**
   * The minimum period for which the gate remains open, in the absence of subsequent triggers
   * (events).
   */
  minimumActivationTime?: string;
  /**
   * The maximum period for which the gate remains open, in the presence of subsequent events.
   */
  maximumActivationTime?: string;
}

/**
 * Limits the frame rate on the input video stream based on the maximumFps property.
 */
export interface MediaGraphFrameRateFilterProcessor {
  /**
   * Polymorphic Discriminator
   */
  type: "#Microsoft.Media.MediaGraphFrameRateFilterProcessor";
  /**
   * The name for this processor node.
   */
  name: string;
  /**
   * An array of the names of the other nodes in the media graph, the outputs of which are used as
   * input for this processor node.
   */
  inputs: MediaGraphNodeInput[];
  /**
   * Ensures that the frame rate of the video leaving this processor does not exceed this limit.
   */
  maximumFps?: string;
}

/**
 * An interface representing DirectMethodsforLiveVideoAnalyticsonIoTEdgeOptions.
 */
export interface DirectMethodsforLiveVideoAnalyticsonIoTEdgeOptions extends AzureServiceClientOptions {
  baseUri?: string;
}

/**
 * Defines values for MediaGraphInstanceState.
 * Possible values include: 'Inactive', 'Activating', 'Active', 'Deactivating'
 * @readonly
 * @enum {string}
 */
export type MediaGraphInstanceState = 'Inactive' | 'Activating' | 'Active' | 'Deactivating';

/**
 * Defines values for MediaGraphParameterType.
 * Possible values include: 'String', 'SecretString', 'Int', 'Double', 'Bool'
 * @readonly
 * @enum {string}
 */
export type MediaGraphParameterType = 'String' | 'SecretString' | 'Int' | 'Double' | 'Bool';

/**
 * Defines values for MediaGraphOutputSelectorProperty.
 * Possible values include: 'mediaType'
 * @readonly
 * @enum {string}
 */
export type MediaGraphOutputSelectorProperty = 'mediaType';

/**
 * Defines values for MediaGraphOutputSelectorOperator.
 * Possible values include: 'is', 'isNot'
 * @readonly
 * @enum {string}
 */
export type MediaGraphOutputSelectorOperator = 'is' | 'isNot';

/**
 * Defines values for MediaGraphRtspTransport.
 * Possible values include: 'Http', 'Tcp'
 * @readonly
 * @enum {string}
 */
export type MediaGraphRtspTransport = 'Http' | 'Tcp';

/**
 * Defines values for MediaGraphMotionDetectionSensitivity.
 * Possible values include: 'Low', 'Medium', 'High'
 * @readonly
 * @enum {string}
 */
export type MediaGraphMotionDetectionSensitivity = 'Low' | 'Medium' | 'High';

/**
 * Defines values for MediaGraphImageScaleMode.
 * Possible values include: 'PreserveAspectRatio', 'Pad', 'Stretch'
 * @readonly
 * @enum {string}
 */
export type MediaGraphImageScaleMode = 'PreserveAspectRatio' | 'Pad' | 'Stretch';

/**
 * Defines values for MediaGraphImageFormatRawPixelFormat.
 * Possible values include: 'Yuv420p', 'Rgb565be', 'Rgb565le', 'Rgb555be', 'Rgb555le', 'Rgb24',
 * 'Bgr24', 'Argb', 'Rgba', 'Abgr', 'Bgra'
 * @readonly
 * @enum {string}
 */
export type MediaGraphImageFormatRawPixelFormat = 'Yuv420p' | 'Rgb565be' | 'Rgb565le' | 'Rgb555be' | 'Rgb555le' | 'Rgb24' | 'Bgr24' | 'Argb' | 'Rgba' | 'Abgr' | 'Bgra';

/**
 * Defines values for MediaGraphImageEncodingFormat.
 * Possible values include: 'Jpeg', 'Bmp', 'Png'
 * @readonly
 * @enum {string}
 */
export type MediaGraphImageEncodingFormat = 'Jpeg' | 'Bmp' | 'Png';

/**
 * Contains response data for the graphTopologyList operation.
 */
export type GraphTopologyListResponse = MediaGraphTopologyCollection & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: MediaGraphTopologyCollection;
    };
};

/**
 * Contains response data for the graphTopologySet operation.
 */
export type GraphTopologySetResponse = MediaGraphTopology & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: MediaGraphTopology;
    };
};

/**
 * Contains response data for the graphTopologyGet operation.
 */
export type GraphTopologyGetResponse = MediaGraphTopology & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: MediaGraphTopology;
    };
};

/**
 * Contains response data for the graphInstanceList operation.
 */
export type GraphInstanceListResponse = MediaGraphInstanceCollection & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: MediaGraphInstanceCollection;
    };
};

/**
 * Contains response data for the graphInstanceSet operation.
 */
export type GraphInstanceSetResponse = MediaGraphInstance & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: MediaGraphInstance;
    };
};

/**
 * Contains response data for the graphInstanceGet operation.
 */
export type GraphInstanceGetResponse = MediaGraphInstance & {
  /**
   * The underlying HTTP response.
   */
  _response: msRest.HttpResponse & {
      /**
       * The response body as text (string format)
       */
      bodyAsText: string;

      /**
       * The response body as parsed JSON or XML
       */
      parsedBody: MediaGraphInstance;
    };
};
